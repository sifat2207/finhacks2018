{
    "collab_server" : "",
    "contents" : "SMOTE <- function(form,data,\n                  perc.over=200,k=5,\n                  perc.under=200,\n                  learner=NULL,...\n)\n        \n        # INPUTS:\n        # form a model formula\n        # data the original training set (with the unbalanced distribution)\n        # minCl  the minority class label\n        # per.over/100 is the number of new cases (smoted cases) generated\n        #              for each rare case. If perc.over < 100 a single case\n        #              is generated uniquely for a randomly selected perc.over\n        #              of the rare cases\n        # k is the number of neighbours to consider as the pool from where\n        #   the new examples are generated\n# perc.under/100 is the number of \"normal\" cases that are randomly\n#                selected for each smoted case\n# learner the learning system to use.\n# ...  any learning parameters to pass to learner\n{\n        \n        # the column where the target variable is\n        tgt <- which(names(data) == as.character(form[[2]]))\n        minCl <- levels(data[,tgt])[which.min(table(data[,tgt]))]\n        \n        # get the cases of the minority class\n        minExs <- which(data[,tgt] == minCl)\n        \n        # generate synthetic cases from these minExs\n        if (tgt < ncol(data)) {\n                cols <- 1:ncol(data)\n                cols[c(tgt,ncol(data))] <- cols[c(ncol(data),tgt)]\n                data <-  data[,cols]\n        }\n        newExs <- smote.exs(data[minExs,],ncol(data),perc.over,k)\n        if (tgt < ncol(data)) {\n                newExs <- newExs[,cols]\n                data <- data[,cols]\n        }\n        \n        # get the undersample of the \"majority class\" examples\n        selMaj <- sample((1:NROW(data))[-minExs],\n                         as.integer((perc.under/100)*nrow(newExs)),\n                         replace=T)\n        \n        # the final data set (the undersample+the rare cases+the smoted exs)\n        newdataset <- rbind(data[selMaj,],data[minExs,],newExs)\n        \n        # learn a model if required\n        if (is.null(learner)) return(newdataset)\n        else do.call(learner,list(form,newdataset,...))\n}\n\n\n\n# ===================================================\n# Obtain a set of smoted examples for a set of rare cases.\n# L. Torgo, Feb 2010\n# ---------------------------------------------------\nsmote.exs <- function(data,tgt,N,k)\n        # INPUTS:\n        # data are the rare cases (the minority \"class\" cases)\n        # tgt is the name of the target variable\n        # N is the percentage of over-sampling to carry out;\n        # and k is the number of nearest neighours to use for the generation\n        # OUTPUTS:\n        # The result of the function is a (N/100)*T set of generated\n        # examples with rare values on the target\n{\n        nomatr <- c()\n        T <- matrix(nrow=dim(data)[1],ncol=dim(data)[2]-1)\n        for(col in seq.int(dim(T)[2]))\n                if (class(data[,col]) %in% c('factor','character')) {\n                        T[,col] <- as.integer(data[,col])\n                        nomatr <- c(nomatr,col)\n                } else T[,col] <- data[,col]\n        \n        if (N < 100) { # only a percentage of the T cases will be SMOTEd\n                nT <- NROW(T)\n                idx <- sample(1:nT,as.integer((N/100)*nT))\n                T <- T[idx,]\n                N <- 100\n        }\n        \n        p <- dim(T)[2]\n        nT <- dim(T)[1]\n        \n        ranges <- apply(T,2,max)-apply(T,2,min) # nilai max-min dari setiap variabel\n        \n        nexs <-  as.integer(N/100) # this is the number of artificial exs generated\n        # for each member of T\n        new <- matrix(nrow=nexs*nT,ncol=p)    # the new cases\n        \n        for(i in 1:nT) {\n                \n                # the k NNs of case T[i,]\n                xd <- scale(T,T[i,],ranges)\n                for(a in nomatr) xd[,a] <- xd[,a]==0\n                dd <- drop(xd^2 %*% rep(1, ncol(xd)))\n                kNNs <- order(dd)[2:(k+1)]\n                \n                for(n in 1:nexs) {\n                        # select randomly one of the k NNs\n                        neig <- sample(1:k,1)\n                        \n                        ex <- vector(length=ncol(T))\n                        \n                        # the attribute values of the generated case\n                        difs <- T[kNNs[neig],]-T[i,]\n                        new[(i-1)*nexs+n,] <- T[i,]+runif(1)*difs\n                        for(a in nomatr)\n                                new[(i-1)*nexs+n,a] <- c(T[kNNs[neig],a],T[i,a])[1+round(runif(1),0)]\n                        \n                }\n        }\n        newCases <- data.frame(new)\n        for(a in nomatr)\n                newCases[,a] <- factor(newCases[,a],levels=1:nlevels(data[,a]),labels=levels(data[,a]))\n        \n        newCases[,tgt] <- factor(rep(data[1,tgt],nrow(newCases)),levels=levels(data[,tgt]))\n        colnames(newCases) <- colnames(data)\n        newCases\n}\n############################################################################\n\n#library-----\nlibrary(dplyr)\nlibrary(pROC)\nlibrary(caret)\nlibrary(earth)\nlibrary(smbinning)\nlibrary(xgboost)\n\n\n# data------\ndata_train=read.csv(\"npl_train.csv\")%>%\n        select(-X)\ndata_test=read.csv(\"npl_test.csv\")%>%\n        select(-X)\n\n#data preparation\n#cek missing data\nsummary(data_train)\nsummary(data_test)\n#tidak ada data missing\n\n\n#features selection----\nvardep=\"flag_kredit_macet\"\nvar_nominal=c(\"kode_cabang\",\"skor_delikuensi\")\ndata_train=data_train%>%\n        mutate_at(vars(one_of(var_nominal)),funs(as.character))%>%\n        mutate_at(vars(one_of(var_nominal)),funs(as.factor))\ndata_test=data_test%>%\n        mutate_at(vars(one_of(var_nominal)),funs(as.character))%>%\n        mutate_at(vars(one_of(var_nominal)),funs(as.factor))\n\nlist_features=list()\n\n#full features\nlist_features[[\"feature_1\"]]=c(\"jumlah_kartu\",\"outstanding\",\"limit_kredit\",\"tagihan\",                            \n                               \"total_pemakaian_tunai\",\"total_pemakaian_retail\",\"sisa_tagihan_tidak_terbayar\",\n                               \"kode_cabang\",\"rasio_pembayaran\" ,\"persentasi_overlimit\" ,\"rasio_pembayaran_3bulan\",\n                               \"rasio_pembayaran_6bulan\",\"skor_delikuensi\",\"jumlah_tahun_sejak_pembukaan_kredit\",\n                               \"total_pemakaian\",\"sisa_tagihan_per_jumlah_kartu\",\"sisa_tagihan_per_limit\",\n                               \"total_pemakaian_per_limit\",\"pemakaian_3bln_per_limit\",\"pemakaian_6bln_per_limit\",\n                               \"utilisasi_3bulan\",\"utilisasi_6bulan\")\n\n\n#feature selection dengan mars\nformu=as.formula(paste(vardep,\"~.\"))\nearth1=earth(formu, data = data_train%>%select_(.dots=c(vardep,list_features[[\"feature_1\"]])))\nfeature1=rownames(evimp(earth1))\nlist_features[[\"feature_2\"]]=feature1\n\n#feature selection dengan information value\niv_table=smbinning.sumiv(data_train%>%select_(.dots=c(vardep,list_features[[\"feature_1\"]])),vardep)\nlist_features[[\"feature_3\"]]=as.character((iv_table%>% filter(IV>=0.02))[,\"Char\"])\n\n\n\n\n#model klasifikasi-----\nlist_model=list()\nthreshold <- 0.5\nfor (i in c(1:3)){\n        #regresi logistik\n        model_glm=glm(formu, \n                      data=data_train%>%select_(.dots=c(vardep,list_features[[paste0(\"feature_\",i)]])),\n                      family = binomial(link=\"logit\"))\n        #validitas\n        data_train$pred <- predict(model_glm, type=\"response\", newdata=data_train)\n        \n        # Calculate the area under the ROC curve\n        roc.curve <- roc(data_train$flag_kredit_macet, data_train$pred, ci=T)\n        \n        \n        # Calculates a cross-tabulation of observed and predicted classes \n        # with associated statistics \n        con=confusionMatrix(factor(data_train$pred>threshold), factor(data_train$flag_kredit_macet==1), positive=\"TRUE\")\n        \n        list_temp=list()\n        list_temp[[\"model\"]]=model_glm\n        list_temp[[\"ROC\"]]=roc.curve\n        list_temp[[\"confusionmatrix\"]]=con\n        list_model[[paste0(\"Model_\",i)]]=list_temp\n        \n        \n        #xgboost\n        var_numerik=list_features[[paste0(\"feature_\",i)]][!list_features[[paste0(\"feature_\",i)]]%in%var_nominal]\n        data_numerik=data_train%>%select_(.dots=c(var_numerik))\n        if(\"kode_cabang\" %in% list_features[[paste0(\"feature_\",i)]]){\n                # convert categorical factor into one-hot encoding\n                region <- model.matrix(~kode_cabang-1,data_train)\n                data_numerik=cbind(data_numerik,region)\n        }\n        if(\"skor_delikuensi\" %in% list_features[[paste0(\"feature_\",i)]]){\n                # convert categorical factor into one-hot encoding\n                delikuensi <- model.matrix(~skor_delikuensi-1,data_train)\n                data_numerik=cbind(data_numerik,delikuensi)\n        }\n        data_matrix <- data.matrix(data_numerik)\n        train_label=data.matrix(data_train%>%select_(.dots=c(vardep)))\n        dtrain <- xgb.DMatrix(data = data_matrix, label=train_label )\n        model_xgboost <- xgboost(data = dtrain, # the data   \n                         nround = 2, # max number of boosting iterations\n                         objective = \"binary:logistic\")  # the objective function\n        \n        #validitas\n        data_train$pred <- predict(model_xgboost, dtrain)\n        \n        # Calculate the area under the ROC curve\n        roc.curve <- roc(data_train$flag_kredit_macet, data_train$pred, ci=T)\n        \n        \n        # Calculates a cross-tabulation of observed and predicted classes \n        # with associated statistics \n        con=confusionMatrix(factor(data_train$pred>threshold), factor(data_train$flag_kredit_macet==1), positive=\"TRUE\")\n        \n        list_temp=list()\n        list_temp[[\"model\"]]=model_xgboost\n        list_temp[[\"ROC\"]]=roc.curve\n        list_temp[[\"confusionmatrix\"]]=con\n        list_model[[paste0(\"Model_\",i+3)]]=list_temp\n}\nrm(list_temp,model_glm,model_xgboost,roc.curve,con, earth1)\n\n\n\n\n###--------------------------------------\n#SMOTE\nset.seed(1234)\ndata_smote=data_train%>%select_(.dots=c(vardep,list_features[[\"feature_1\"]]))\ndata_smote$flag_kredit_macet=as.character(data_smote$flag_kredit_macet)\ndata_smote$flag_kredit_macet=as.factor(data_smote$flag_kredit_macet)\ndata_smote <- SMOTE(flag_kredit_macet ~ ., \n                    data=data_smote,\n                    perc.over = 200, perc.under=300)\ndata_smote$flag_kredit_macet=as.character(data_smote$flag_kredit_macet)\ndata_smote$flag_kredit_macet=as.numeric(data_smote$flag_kredit_macet)\n\n# convert categorical factor into one-hot encoding\nregion_smote <- model.matrix(~kode_cabang-1,data_smote)\ndelikuensi_smote <- model.matrix(~skor_delikuensi-1,data_smote)\ndata_numerik_smote=data_smote%>%select_(.dots=c(var_numerik))\ndata_numerik_smote=cbind(data_numerik_smote,region_smote,delikuensi_smote)\n\ndata_matrix_smote <- data.matrix(data_numerik_smote)\ntrain_label_smote=data.matrix(data_smote%>%select_(.dots=c(vardep)))\ndtrain_smote <- xgb.DMatrix(data = data_matrix_smote, label=train_label_smote )\nmodel_xgboost_smote <- xgboost(data = dtrain_smote, # the data   \n                         nround = 2, # max number of boosting iterations\n                         objective = \"binary:logistic\")  # the objective function\n\n#validitas\ndata_smote$pred <- predict(model_xgboost_smote, dtrain_smote)\n\n# Calculate the area under the ROC curve\nroc.curve <- roc(data_smote$flag_kredit_macet, data_smote$pred, ci=T)\n\n\n# Calculates a cross-tabulation of observed and predicted classes \n# with associated statistics \ncon=confusionMatrix(factor(data_smote$pred>threshold), factor(data_smote$flag_kredit_macet==1), positive=\"TRUE\")\n\n\n#####\n#xgboost\nvar_numerik=list_features[[paste0(\"feature_\",1)]][!list_features[[paste0(\"feature_\",1)]]%in%var_nominal]\ndata_numerik=data_train%>%select_(.dots=c(var_numerik))\nif(\"kode_cabang\" %in% list_features[[paste0(\"feature_\",i)]]){\n        # convert categorical factor into one-hot encoding\n        region <- model.matrix(~kode_cabang-1,data_train)\n        data_numerik=cbind(data_numerik,region)\n}\nif(\"skor_delikuensi\" %in% list_features[[paste0(\"feature_\",i)]]){\n        # convert categorical factor into one-hot encoding\n        delikuensi <- model.matrix(~skor_delikuensi-1,data_train)\n        data_numerik=cbind(data_numerik,delikuensi)\n}\ndata_matrix <- data.matrix(data_numerik)\ntrain_label=data.matrix(data_train%>%select_(.dots=c(vardep)))\ndtrain <- xgb.DMatrix(data = data_matrix, label=train_label )\n\ndata_train$pred <- predict(model_xgboost_smote, dtrain)\nroc.curve_test <- roc(data_train$flag_kredit_macet, data_train$pred, ci=T)\n\n\n# Calculates a cross-tabulation of observed and predicted classes \n# with associated statistics \ncon_test=confusionMatrix(factor(data_train$pred>threshold), factor(data_train$flag_kredit_macet==1), positive=\"TRUE\")\n",
    "created" : 1536219146385.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2680950477",
    "id" : "CD670192",
    "lastKnownWriteTime" : 1536549993,
    "last_content_update" : 1536549993,
    "path" : "E:/Sifat/finhacks2018/boluemprit/npl-20180815/npl.R",
    "project_path" : "npl.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}